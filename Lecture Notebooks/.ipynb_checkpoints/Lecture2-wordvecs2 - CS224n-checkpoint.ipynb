{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS224n: NLP with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Word Vectors and Word Senses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our usual example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* King - Man ~= Idea of Kingship without the Man Part\n",
    "* +Woman = add Woman Idea to it\n",
    "* => Get Queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot words on a scatter plot:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for word, (x,y) in zip(words, twodim):\n",
    "    plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec : Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 big matrices:\n",
    "* 1 that represents every outside word's vector $U$\n",
    "* 1 which represents every center word's vector $V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$U = \\begin{bmatrix}[outside\\,word\\,vector\\,1]\n",
    "\\\\ \\vdots\n",
    "\\\\ [outside\\,word\\,vector\\,n] \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V = \\begin{bmatrix}[center\\,word\\,vector\\,1]\n",
    "\\\\ \\vdots\n",
    "\\\\ [center\\,word\\,vector\\,n] \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We multiply $U$ by a center word $v_{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "U \\cdot v_{4} &= \\begin{bmatrix}[outside\\,word\\,vector\\,1]\n",
    "\\\\ \\vdots\n",
    "\\\\ [outside\\,word\\,vector\\,n] \\end{bmatrix}\n",
    "\\cdot v_{4}\n",
    "\\\\ &=\\begin{bmatrix}[similarity\\,(u_{1}, v_{4})]\n",
    "\\\\ \\vdots\n",
    "\\\\ [similarity\\,(u_{n}, v_{4})] \\end{bmatrix}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We apply softmax to get a vector of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$softmax(U\\cdot u_{4})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark 1\n",
    "**The outside words that are predicted will always be the same !!**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "House house [center word] house house\n",
    "if P(house|center word) = max P(context word|center word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our model will give a reasonably high probability estimate to all words that occur in the context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark 2\n",
    "The words 'and', 'the', 'of', ... will have very high frequency with all the other words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark 3\n",
    "The 2D-projections of the word clouds are very misleading\n",
    "\n",
    "In very high dimensional space, a word can be close to lots of other words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "* Minimise cost function $J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:** \n",
    "* For current value of $\\theta$, calculate the gradient of $J(\\theta)$\n",
    "* Take a small step in the direction of negative gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta^{new} = \\theta^{old} - \\alpha \\nabla_{\\theta}J(\\theta) $$ where $\\alpha$ is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Stochastic Gradient Decsent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $J(\\theta)$ is a function of all windows in the corpus!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Stochastic Gradient Descent !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeatedly sample windows\n",
    "* Update our parameters after going through each window\n",
    "* The parameters are updated with amazingly noisy gradient, but it doesn't matter too much \n",
    "* It allows us to go much quicker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark 1\n",
    "\n",
    "Choose mini-batch size of 32, 64, or other powers of 2, as they allow to make the most out of parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark 2\n",
    "\n",
    "* In each window, we have a certain number of words $2m+1$\n",
    "* Our parameter vector $\\theta$ is in $\\mathbb{R}^{2dV}$, which is much bigger\n",
    "* Hence, $\\nabla_{\\theta} J(\\theta)$ is a very sparce matrix\n",
    "\n",
    "=> **Idea:**\n",
    "\n",
    "Only update the word vectors that appear in our window!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why 2 vectors for each word?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is easy to optimize\n",
    "* We just average them to get a unique word vector in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Model variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Skip-gram: Predict outside words (position independent) given center word\n",
    "2. Continuous Bag of Words: predict center word from a Bag of context words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results we get via these 2 methods are quite similar, as the dot product is symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:**\n",
    "\n",
    "Train binary logistic regression for a true pair (center word & word in its context window)\n",
    "\n",
    "VS\n",
    "\n",
    "Several noise pairs (center word & a random word) = Negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maximize probability that real outside word appears\n",
    "* Minimize probability that random words appear around center word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample these words using the Unigram distribution to determine their probability of being sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(w) = U(w)^{3/4} / Z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The 3/4 power helps to make the most frequent words appear more often, and the less frequent words appear more\n",
    "* $Z$ is a normalization factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:**\n",
    "\n",
    "The sigmoid function is like the softmax function for 2 classes: maps our values to a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Senses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
